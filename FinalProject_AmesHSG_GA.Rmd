---
title: "FinalProject_AmesHSG"
author: "Jaih, Katie, Andy, Anum"
date: "3/12/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r package_load}
library(ggplot2) # graphics library
library(ISLR)    # contains code and data from the textbook
library(knitr)   # contains kable() function
library(class)   # contains knn
library(tree)    # For the tree-fitting 'tree' function
library(rpart)   # For nicer tree fitting
library(partykit)  # For nicer tree plotting
library(MASS)    # For Boston data
library(randomForest) # For random forests and bagging
library(ggcorrplot)

options(scipen = 4)  # Suppresses scientific notation


library(tidyverse)
library(knitr)
library(GGally)
```

## Section 1: Data Clean-Up and Exploration

<font color="#800000">
We are going to examine the housing data-set to pick out some key characteristics, trends and summaries for our model evaluations with the eventual goal of developing a sales price prediction model that can be used improve  price listings and clients advice on home improvement projects. The following section will aim to clean-up the data for our use and identify general trends in sales prices across time, neighborhood, and other key home characteristics. 
</font>

```{r}
#read in data
housing.raw <- read.csv("AmesHousing.csv")
```

```{r}
#summary(housing.raw)
glimpse(housing.raw)
#Checking the class of each variable
categories.housing <- data.frame(variabletype=sapply(housing.raw,class))
categories.housing
```
```{r}
numeric_variables <- table(categories.housing[categories.housing['variabletype'] == 'integer'])
numeric_variables
categorical_variables <- table(categories.housing[categories.housing['variabletype'] == 'character'])
categorical_variables
```


```{r}
#Checking the number of NA values in the data-set to evaluate clean-up
sum(is.na(housing.raw))
```

<font color="#800000">
On first glance, we see a few salient features within the dataset with 39 integer variables which include: 
-MS.Subclass
-Lot.Frontage
- Lot.Area
- Overall.Qual
- Overall.Cond
- Year.Built
- Year.Remod.Add
- Full.Bath				
- Half.Bath		
- Bedroom.AbvGr			
- Kitchen.AbvGr
- TotRms.AbvGrd
- Mo.Sold			
- Yr.Sold	
- SalePrice	

We see 43 character variables which include: 
- MS.Zoning
- Utilities
- Neighborhood
- Heating
- Central.Air
- Kitchen.Qual

The dataset also has `r sum(is.na(housing.raw))` NA values. However, in most cases this corresponds to the characteristic not being present in the house; therefore, we will proceed to change these 'NA' values to "None" where it makes sense to not lose any relevant data. e.g --> Pool.QC
</font>

```{r}
length.data.raw <- nrow(housing.raw)

housing.clean <- housing.raw

#calculate the number of NA's in non catetorical columns
# for (j in 1: ncol(housing.clean)){
#   a <- sum(is.na(housing.clean[,j]))
#   print(paste(j,":",a))
# }

#Replace empty strings with NA so that ensuing functions can mutate them
#Code example taken from: (https://stackoverflow.com/questions/51449243/how-to-replace-empty-string-with-na-in-r-dataframe)
housing.raw[housing.raw==""] <- NA

#Replace NA values from data adapted from (https://stackoverflow.com/questions/8161836/how-do-i-replace-na-values-with-zeros-in-an-r-dataframe)

housing.clean <- housing.raw %>% 
  mutate_if(is.character, ~replace(., is.na(.), "None")) %>%
  mutate_if(is.numeric, ~replace(., is.na(.), 0))

#Identifying empty strings
housing.processed <- housing.clean %>%
  mutate(Bsmt.Cond = factor(Bsmt.Cond, levels = c("Ex", "Gd", "TA", "Fa", "Po", "None"))) %>%
  mutate(Bsmt.Exposure = factor(Bsmt.Exposure, levels = c("Gd","Av","Mn","No", "None"))) %>%
  mutate(Fireplace.Qu = factor(Fireplace.Qu, levels = c("Ex", "Gd", "TA", "Fa", "Po", "None"))) %>%
  mutate(Garage.Qual = factor(Garage.Qual, levels = c("Ex", "Gd", "TA", "Fa", "Po", "None"))) %>%
  mutate(Bsmt.Qual = factor(Bsmt.Qual, levels = c("Ex", "Gd", "TA", "Fa", "Po", "None"))) %>%
  mutate(BsmtFin.Type.1 = factor(BsmtFin.Type.1, levels = c("GLQ", "ALQ", "BLQ", "Rec", "LwQ", "Unf", "None"))) %>%
  mutate(BsmtFin.Type.2 = factor(BsmtFin.Type.2, levels = c("GLQ", "ALQ", "BLQ", "Rec", "LwQ", "Unf", "None"))) %>%
  mutate(Heating.QC = factor(Heating.QC, levels = c("Ex", "Gd", "TA", "Fa", "Po"))) %>%
  mutate(Kitchen.Qual = factor(Kitchen.Qual, levels = c("Ex", "Gd", "TA", "Fa", "Po"))) %>%
  mutate(Exter.Qual = factor(Exter.Qual, levels = c("Ex", "Gd", "TA", "Fa"))) %>%
  mutate(Exter.Cond = factor(Exter.Cond, levels = c("Ex", "Gd", "TA", "Fa", "Po"))) %>%
  mutate(Functional = factor(Functional, levels = c("Typ", "Min1", "Min2", "Mod", "Maj1", "Maj2", "Sev", "Sal"))) %>%
  mutate(Garage.Finish = factor(Garage.Finish, levels = c("Fin", "RFn", "Unf", "None"))) %>%
  mutate(Pool.QC = factor(Pool.QC, levels = c("Ex", "Gd", "TA", "Fa", "None"))) %>%
  mutate(Lot.Shape = factor(Lot.Shape, levels = c("Reg","IR1","IR2","IR3"))) %>%
  mutate(Land.Slope = factor(Land.Slope, levels = c("Gtl","Mod","Sev"))) %>%
  mutate(Overall.Qual = factor(Overall.Qual, levels = c(10, 9, 8, 7, 6, 5, 4, 3, 2, 1))) %>%
  mutate(Overall.Cond = factor(Overall.Cond, levels = c(9, 8, 7, 6, 5, 4, 3, 2, 1))) %>%
  mutate(MS.SubClass = recode_factor(MS.SubClass, 
                                     '20' = "1-STORY 1946N",
                                     '30' = "1-STORY 1945O",
                                     '40' = "1-STORY UF.ATTIC.A",
                                     '45' = "1.5 STORY UF.A",
                                     '50' = "1.5-STORY F.ATTIC.A",
                                     '60' = "2-STORY 1946N",
                                     '70' = "2-STORY 1945O",
                                     '75' = "2.5-STORY A",
                                     '80' = "MULTILVL",
                                     '85' = "SPLIT FOYER",
                                     '90' = "DUPLEX.A",
                                     '120' = "1-STORY-PUD 1946N",
                                     '150' = "1.5-STORY-PUD.A",
                                     '160' = "2-STORY-PUD 1946N",
                                     '180' = "PUD-MULTILVL",
                                     '190' = "2 FAM CONV.A"))

##CHANGE THIS BACK TO HOUSING CLEAN
housing.train <- subset(housing.processed, Yr.Sold < 2010)
housing.train <- subset(housing.train, select = MS.SubClass:SalePrice)

housing.test <- subset(housing.processed, Yr.Sold == 2010)
housing.test <- subset(housing.test, select = MS.SubClass:SalePrice)

#terminology used is N for New, O for Old, A for All

        #20	1-STORY 1946 & NEWER ALL STYLES
        #30	1-STORY 1945 & OLDER
        #40	1-STORY W/FINISHED ATTIC ALL AGES
        #45	1-1/2 STORY - UNFINISHED ALL AGES
        #50	1-1/2 STORY FINISHED ALL AGES
        #60	2-STORY 1946 & NEWER
        #70	2-STORY 1945 & OLDER
        #75	2-1/2 STORY ALL AGES
        #80	SPLIT OR MULTI-LEVEL
        #85	SPLIT FOYER
        #90	DUPLEX - ALL STYLES AND AGES
       #120	1-STORY PUD (Planned Unit Development) - 1946 & NEWER
       #150	1-1/2 STORY PUD - ALL AGES
       #160	2-STORY PUD - 1946 & NEWER
       #180	PUD - MULTILEVEL - INCL SPLIT LEV/FOYER
       #190	2 FAMILY CONVERSION - ALL STYLES AND AGES
```



* only 198 entries have data for paved 

* Replaced all NA's with "NONE", so as to ensure that R counts it as a category

* Created levels for all data with c("Ex", "Gd", "TA", "Fa", "Po", "None"): BsmtCond, BsmtExposure, FireplaceQu, GarageQual, GarageCond, BsmtQual
- Corr:
- GarageQual, GarageCond

* Created levels for all data with  c("GLQ", "ALQ", "BLQ", "REC", "LwQ", "UNF", "None"): BsmtFinType1, BsmtFinType2

* ?Need to look at BsmtFinType1, BsmtFinType2 relationship, because it seems that unf/0 is for houses with one basement area

* Created levels for all data with c("Ex", "Gd", "TA", "Fa", "Po"): HeatingQC, KitchenQual, ExterQual, ExterCond

* Created levels for all data with  c("Typ", "Min1", "Min2", "Mod", "Maj1", "Maj2", "Sev", "Sal"): Functional

* Created levels for all data with  c("Fin", "RFn", "Unf", "None"): GarageFinish

* Created levels for all data with  c("Ex", "Gd", "TA", "Fa", "None"): PoolQC

* Created levels for all data with  c("Reg","IR1","IR2","IR3"): LotShape

* Created levels for all data with  c("Gtl","Mod","Sev"): LandSlope

* Created levels for all data with  c(10, 9, 8, 7, 6, 5, 4, 3, 2, 1): OverallQual, OverallCond

* Separate train and test
# Initial Data Plots and Summaries

<font color="#800000">
Now that we've done some cleaning; let's go on to explore our main dependent variable: SalePrice. 
</font>

# Do we want to run summary statistics on whole data Set or just train?
```{r, warning = FALSE}
summary(housing.processed$SalePrice)

# Histogram
qplot(housing.processed$SalePrice) + xlab("Sales Price") + ggtitle("Distribution of Sale Price in Data") 
```

<font color="#800000">
The data seems to have a slight right skewed distribution with a mean pricing of 184,386. When modeling this outcome, a strong argument can be made that the price should be log-transformed. A logarithmic price scale uses the percentage of change to plot data points, so, the scale prices are not positioned equidistantly. Furthermore, this will ensure that no houses would be predicted with negative sale prices and that errors in predicting expensive houses will not have an undue influence on the model. 
</font>

<font color="#800000">
For a better sense of the numeric variables that constitute area and key characteristics, we look at the histogram for a few. Given the importance of property size metrics, we quickly zoomed in on “GrLivArea”, “LotArea” and “GarageArea” as potential explanatory variables.
</font>

```{r}
par(mfrow = c(3, 3))
hist(housing.processed$Lot.Frontage, breaks = 20, main = "Feet of Street Connected to Property", border="red", col="steelblue")
hist(housing.processed$Lot.Area, breaks = 20, main = "Lot Size in Square Feet", border="red", col="steelblue")
hist(housing.processed$Gr.Liv.Area, breaks = 20, main = "Above Ground Living Area", border="red", col="steelblue")
hist(housing.processed$Pool.Area, breaks = 20, main = "Pool Area", border="red", col="steelblue")
hist(housing.processed$Total.Bsmt.SF, breaks = 20, main = "Total Basement Square Feet", border="red", col="steelblue")
hist(housing.processed$Year.Built, breaks = 20, main = "Year Built", border="red", col="steelblue")
hist(housing.processed$Full.Bath, breaks = 20, main = "Full Bath", border="red", col="steelblue")
hist(housing.processed$Bedroom.AbvGr, breaks = 20, main = "Bedroom Above Ground", border="red", col="steelblue")
hist(housing.processed$Garage.Area, breaks = 20, main = "red", border="red", col="steelblue")
```

<font color="#800000">
Intuitively, neighbourhoods are a relevant predictor for Sale Price, so we proceed to make summary tables and boxplots to visualize this relationship. 
</font>

```{r, warning = FALSE}
neighborhood.eval <- housing.processed %>%
  group_by(Neighborhood) %>%
  summarize(average.price = mean(SalePrice), 
            median.price = median(SalePrice), .groups = "keep")

neighborhood.eval
```
```{r}
#Neighborhood
ggplot(data = housing.processed, aes(x =SalePrice , y = Neighborhood)) +
  geom_boxplot() + ggtitle("Neighborhood vs Sales Price")
```

<font color="#800000">
StoneBr, NridgeHt and NoRidge seem to be the more pricier neighborhoods. Our intuition was spot on: the sales price varies with different neighborhoods, so we should definitely include this in our model as a predictor.

Other characteristics that stands out is overall quality of the house and kitchen quality . We expect there to be a strong linear relationship between quality and prices. The poorer the quality, the lower the price. These can be strong predictors in our model.
</font>

```{r}
qual.plot <- ggplot(housing.processed, aes(Overall.Qual,SalePrice)) + geom_jitter(alpha = 0.5, color = "blue")
qual.plot
```

```{r}
qual.plot2 <- ggplot(housing.processed, aes(Kitchen.Qual,SalePrice)) + geom_jitter(alpha = 0.5, color = "blue")
qual.plot2
```
```{r}
#MSSubclass
ggplot(data = housing.processed, aes(x = SalePrice, y = MS.SubClass)) +
  geom_boxplot()
```

```{r}
housing.processed %>% ggplot(aes(x = Yr.Sold, y= SalePrice/1000)) + geom_jitter() + stat_smooth(method = "lm") + ggtitle("Housing Prices Between 2006-2010") + xlab("Year Sold") + ylab("Price in $1000")
```

<font color="#800000">
The dataset covers 2006-2010 which falls within the years of the Great Recession. The Great Recession was a period of marked general decline observed in national economies globally that began in December 2007 and ended in June 2009.  Home prices fell approximately 30 percent, on average, from their mid-2006 peak to mid-2009. Source URL: https://www.federalreservehistory.org/essays/great-recession-of-200709.

Given this fact, it is actually surprising that the dataset does not reflect a decrease in prices; but a stagnant rate across the five years.
</font>


<font color="#800000">
We also think it's meaningful to explore the relationship between price and year built. Generally, newer houses tend to be more expensive but there could elite neighborhoods with older houses that have a higher price. Let's see if this could be valuable for our model.
</font>


```{r}
year.plot <- ggplot(housing.processed, aes(Year.Built,SalePrice)) + geom_jitter(alpha = 0.5, color = "blue")
year.plot
```

<font color="#800000">
Just as we expected, we see that newer houses tend to be more expensive in the dataset. However, there are a few outliers which exhibit the opposite: very old houses appear to increase in price. Perhaps these could be considered as "old century homes" built in years prior to 1920 which would no longer correspond to a price decrease with age. We would have to re-evalute this in our prediction model. 
</font>


```{r}
## Dig a bit deeper into any areas that show trends
#Sale Condition

ggplot(data = housing.processed, aes(x = Sale.Condition, y = SalePrice)) +
  geom_boxplot()

#OverallCond

ggplot(data = housing.processed, aes(x = Overall.Cond, y = SalePrice)) +
  geom_boxplot()

#OverallQual

ggplot(data = housing.processed, aes(x = Overall.Qual, y = SalePrice)) +
  geom_boxplot()

#Functional
ggplot(data = housing.processed, aes(x = Functional, y = SalePrice)) +
  geom_boxplot()

#Kitchen Quality

ggplot(data = housing.processed, aes(x = Kitchen.Qual, y = SalePrice)) +
  geom_boxplot()

#BsmtCond

ggplot(data = housing.processed, aes(x = Bsmt.Cond, y = SalePrice)) +
  geom_boxplot()

#Extercond

ggplot(data = housing.processed, aes(x = Exter.Cond, y = SalePrice)) +
  geom_boxplot()

#HouseStyle
ggplot(data = housing.processed, aes(x = House.Style, y = SalePrice)) +
  geom_boxplot()

#BldgType

ggplot(data = housing.processed, aes(x = Bldg.Type, y = SalePrice)) +
  geom_boxplot()


#Sale Type

ggplot(data = housing.processed, aes(x = Sale.Type, y = SalePrice)) +
  geom_boxplot()


```

<font color="#800000">
For the purpose of making out model leaner, we will explore variables that might exhibit high collinearity. Intuitively, it looks like there are some extra variables which may not be necessary. For example, our expectation is that Lot.Frontage and Lot.Area will be highly correlated. Similarly, Bedroom.AbvGr and TotRms.AbvGrd might follow a similar trend. We look further into the correlations between the numeric variables:
</font>


```{r}
# create a subset of variable names
myvars <- c("Lot.Frontage","Lot.Area", "Year.Built", "Year.Remod.Add", "Mas.Vnr.Area","Total.Bsmt.SF", "Bsmt.Unf.SF", "BsmtFin.SF.2","BsmtFin.SF.1", "X1st.Flr.SF","X2nd.Flr.SF", "Low.Qual.Fin.SF","Gr.Liv.Area", "Bsmt.Full.Bath","Bsmt.Half.Bath", "Full.Bath", "Half.Bath", "Bedroom.AbvGr","Kitchen.AbvGr", "Fireplaces", "TotRms.AbvGrd","Garage.Yr.Blt","Garage.Cars", "Garage.Area", "Wood.Deck.SF",	"Open.Porch.SF","Enclosed.Porch", "X3Ssn.Porch",	"Screen.Porch", "Pool.Area", "SalePrice", "Mo.Sold","Yr.Sold")

sub.house <- housing.processed[myvars]

#Create a data frame for variables that are correlated 
corr.sub.house <- round(cor(sub.house),2)
corr.table <- as.data.frame(as.table(corr.sub.house))
names(corr.table)[1] <- "Variable 1"
names(corr.table)[2] <- "Variable 2"

#Find the variables which are strongly correlated as per rule of 0.6
corr.subset <- subset(corr.table,  Freq > 0.6 | Freq < -0.6) 
corr.subset

```

```{r}
categories.housing
```


<font color="#800000">
Based on intuition, we split the variables into sub-categories to explore collinearity. 
</font>

```{r}
#Features
hsg.features <- c("Utilities", "Bldg.Type","House.Style","Roof.Style",
                  "Roof.Matl","Exterior.1st","Exterior.2nd","Foundation",
                  "Bsmt.Unf.SF","Total.Bsmt.SF","Heating","Heating.QC",
                  "Central.Air","Electrical","Fireplaces","Garage.Type",
                  "Garage.Finish","Garage.Area","Paved.Drive","Misc.Feature",
                  "Misc.Val")

#Quality
hsg.quality <- c("Overall.Qual","Overall.Cond","Exter.Qual","Exter.Cond",
                 "Bsmt.Cond","Bsmt.Qual","Bsmt.Exposure","BsmtFin.Type.1",
                 "BsmtFin.Type.2","Heating.QC","Fireplace.Qu","Garage.Finish",
                 "Garage.Qual","Garage.Cond","Fence","Misc.Val","Pool.QC",
                 "Sale.Condition")

#Sales Criteria
sales.crit <- c("MS.SubClass", "MS.Zoning", "Year.Built", "Year.Remod.Add",
                "Mo.Sold", "Yr.Sold", "Sale.Type")

# Use the following characterstics to make correlation plots and pick out the most relevant 
#Geo-Spatial Characteristics
geo.char <- c("Lot.Area","Lot.Frontage","Mas.Vnr.Area","X1st.Flr.SF","X2nd.Flr.SF","Garage.Area","Wood.Deck.SF",
              "Open.Porch.SF","Pool.Area", "Low.Qual.Fin.SF","Gr.Liv.Area")
  
  
ggpairs(data = housing.processed[,geo.char[1:5]])

#Basement/Bath Redundancies
bb.crit <- c("BsmtFin.SF.1", "BsmtFin.SF.2", "Bsmt.Unf.SF", "Total.Bsmt.SF", 
             "Bsmt.Full.Bath", "Bsmt.Half.Bath", "Full.Bath","Half.Bath")

#Above Ground
ag.crit <- c("Bedroom.AbvGr", "Kitchen.AbvGr", "TotRms.AbvGrd", "Gr.Liv.Area")

#Deck/Porch
dp.crit <- c("Wood.Deck.SF", "Open.Porch.SF", "Enclosed.Porch","X3Ssn.Porch","Screen.Porch")


sub.house.geo <- housing.processed[geo.char]
corr.sub.house.geo <- round(cor(sub.house.geo),2)

sub.house.bb.crit <- housing.processed[bb.crit]
corr.sub.house.bb <- round(cor(sub.house.bb.crit),2)

sub.house.ag.crit <- housing.processed[ag.crit]
corr.sub.house.ag <- round(cor(sub.house.ag.crit),2)

sub.house.dp.crit <- housing.processed[dp.crit]
corr.sub.house.dp <- round(cor(sub.house.dp.crit),2)

```

```{r, fig.width = 15}
#Use ggcorrplot to graph correlation. 
ggcorrplot(corr.sub.house.geo, hc.order = TRUE, outline.color = 'white', lab = TRUE, title = "Correlation between Geo-Spatial Characteristics in Housing Dataset", legend.title = "Correlation")
```

```{r, fig.width = 15}
#Use ggcorrplot to graph correlation. 
ggcorrplot(corr.sub.house.bb, hc.order = TRUE, outline.color = 'white', lab = TRUE, title = "Correlation between Basement-Bath Characteristics in Housing Dataset", legend.title = "Correlation")
```
```{r, fig.width = 15}
#Use ggcorrplot to graph correlation. 
ggcorrplot(corr.sub.house.ag, hc.order = TRUE, outline.color = 'white', lab = TRUE, title = "Correlation between Basement-Bath Characteristics in Housing Dataset", legend.title = "Correlation")
```
```{r, fig.width = 15}
#Use ggcorrplot to graph correlation. 
ggcorrplot(corr.sub.house.dp, hc.order = TRUE, outline.color = 'white', lab = TRUE, title = "Correlation between Basement-Bath Characteristics in Housing Dataset", legend.title = "Correlation")
```

# Inital Linear Regressions 

<font color="#800000">
As an initial simple model we will consider a few variables to be important determinants of the price of a property:

- Overall.Qual: The quality rating (from 1 to 10).
- Kitchen.Qual
- Neighborhood: Neighborhoods vary across location as per our EDA.
- MS.SubClass
- MS.Zoning.
- Lot.Area
- Year.Built 
- Total.Bsmt.SF
- Gr.Liv.Area
- Open.Porch.SF
- Pool.Area
</font>

```{r}
model.fit.1 <- lm(SalePrice ~
                 Overall.Qual +
                Kitchen.Qual +
                 Neighborhood +
                 MS.SubClass +
                 MS.Zoning +
                Lot.Area +
                 Year.Built +
                 Total.Bsmt.SF + 
                 Gr.Liv.Area +
                Open.Porch.SF +
                Pool.Area,
               data = housing.train)
summary(model.fit.1)

#lm.preds = predict(model.fit.1, newdata=housing.test)
#Error in model.frame.default(Terms, newdata, na.action = na.action, xlev = object$xlevels) : 
  #factor Kitchen.Qual has new levels Po
# I think We should refactor this to be numeric...
```


Let's see if subset selection produces similar results to our own intuitive selection.

```{r}
library(leaps)
# Categorical Vars - MSSubClass, MSZoning, Street, Alley, Lot Shape, LandContour, Utilities, LotConfig, LandSlope, Neighborhood, Condition1, Condition2, BldgType, HouseStyle, OverallQual, OverallCond, YearBuilt, YearRemodAdd, RoofStyle, RoofMat1, Exterior1st, Exterior2nd, MasVnrType, MasVnrArea, ExterQual,ExterCond, Foundation, BsmtQual, BsmtExposure, BsmtFinType1, BsmtFinType2, Heating, HeatingQC, CentralAir, Electrical, KitchenQual, TotRmsAbvGrd, Functional, FireplaceQu, GarageType, GarageYrBlt, GarageFinish, GarageQual, GaraggeCond, PavedDrive, PoolQC, Fence, MiscFeature, MoSold, YrSold, SaleType, SaleCondition

# Continuous Variables - LotFrontage, LotArea, OverallQual,OverallCond, YearBuilt, 1stFlrSF, 2ndFlrSF, LowQualFinSF, GrLivArea, BsmtFullBath, BsmtHalfBath, FullBath, HalfBath, Bedroom, Kitchen, TotRmsAbvGrd, Fireplaces, GarageCars, GarageArea, WoodDeckSF, OpenPorchSF, EnclosedPorch, 3SsnPorch, ScreenPorch, PoolArea, MiscVal 
regfit.backward=regsubsets(SalePrice~.,data=housing.train,nvmax=11,method="forward")
```

# Functions to Evaluate models
```{r}

X.Train <- subset(housing.train, select = -SalePrice)
Y.Train <- subset(housing.train, select = SalePrice)

X.Test <- subset(housing.test, select = -SalePrice)
Y.Test <- subset(housing.test, select = SalePrice)


#Functions to calculate Error Terms
calcMSE <- function(preds, actual) {
  mean((lasso.pred-actual)^2)
}

calcRMSE <- function(preds, actual) {
  sqrt(calcMSE(preds, actual))
}

calcMAE <- function(preds, actual) {
  abs(mean(preds-actual))
}

calcRelErr <- function(preds, actual) {
  (preds - actual)/actual
}
```

# Lasso Model

```{r}
library(glmnet)
test <- which(housing.clean$Yr.Sold==2010)
train <- which(housing.clean$Yr.Sold<2010)
housing.lasso = subset(housing.clean,select=MS.SubClass:SalePrice)

#Lasso 
x <- model.matrix(SalePrice~.,housing.lasso)[,-1]
y <- housing.lasso$SalePrice

#Create Lasso Models for CV
grid=10^seq(10,-2, length =100)
lasso.mod=glmnet(x[train,],y[train],alpha=1,lambda=grid)
plot(lasso.mod)

#Run CV
set.seed(1)
cv.out=cv.glmnet(x[train,],y[train],alpha=1)
plot(cv.out)

#Find BestLam from CV
bestlam=cv.out$lambda.min


lasso.coef = predict(lasso.mod,type="coefficients",s=bestlam)[1:40,]
kable(lasso.coef[lasso.coef!=0])
length(lasso.coef[lasso.coef!=0])

lasso.pred=predict(lasso.mod,s=bestlam,newx=x[test,])

paste("MAE: ",calcMAE(preds=lasso.pred, y[test]))
paste("RMSE: ",calcRMSE(preds=lasso.pred, y[test]))
paste("Mean RelErr: ", mean(calcRelErr(preds=lasso.pred, y[test])))
```


# Random Forests
```{r}
set.seed(1)
rf <- randomForest(SalePrice ~ .,data=housing.train, mtry=25, importance=TRUE)
rf

varImpPlot(rf,n.var = 20)

rf.preds <- predict(rf, newdata = housing.test)
paste("MAE: ",calcMAE(preds=rf.preds, y[test]))
paste("RMSE: ",calcRMSE(preds=rf.preds, y[test]))
paste("Mean RelErr: ", mean(calcRelErr(preds=rf.preds, y[test])))


```